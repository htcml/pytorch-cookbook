{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.code = nn.Linear(128, 10)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(512, input_size),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.code(out)\n",
    "        out = self.decoder(out)\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (code): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=784, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(784).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.0533\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0371\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0331\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0279\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0232\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0251\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0225\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0222\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0207\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0195\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0187\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0174\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0192\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0195\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0196\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0181\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0182\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0200\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0167\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0172\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0176\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0158\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0167\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0163\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0162\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0158\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0159\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0143\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0139\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0148\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        #print(i, images.shape)\n",
    "        #labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, images)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 784])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "idx = 1\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(images[idx].numpy().reshape(28,28), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(outputs[idx].numpy().reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images2 = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images2)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
